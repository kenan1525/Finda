import requests
import random
import re
import os
from urllib.parse import urlparse, parse_qs, quote
from django.conf import settings
import time

CACHE = {}

# -------------------------
# TEXT NORMALIZATION & UTILS
# -------------------------
def normalize_title(title):
    text = title.lower()
    text = re.sub(r"[^a-z0-9 ]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def extract_real_link(google_link, title="", source=""):
    """
    Google'Ä±n hapis linklerini kÄ±rar. 
    EÄŸer link temizlenemiyorsa, ilgili maÄŸazanÄ±n arama sayfasÄ±na yÃ¶nlendirir.
    """
    if not google_link or google_link == "#":
        return "#"
    
    source_lower = (source or "").lower()
    query_encoded = quote(title or "")

    # 1. Google iÃ§ermiyorsa zaten direkt linktir
    if "google.com" not in google_link:
        return google_link

    # 2. URL Parametrelerini temizlemeyi dene
    try:
        parsed_url = urlparse(google_link)
        params = parse_qs(parsed_url.query)
        
        # 'adurl' veya 'url' parametreleri varsa Ã§ek
        for key in ['adurl', 'url', 'q']:
            if params.get(key):
                clean = params.get(key)[0]
                if clean.startswith("http"):
                    return clean
    except:
        pass

    # 3. ZORLAYICI MANTIK (Fallback): Google bizi bÄ±rakmÄ±yorsa biz kendi linkimizi yaparÄ±z
    if "trendyol" in source_lower:
        return f"https://www.trendyol.com/sr?q={query_encoded}"
    elif "amazon" in source_lower:
        return f"https://www.amazon.com.tr/s?k={query_encoded}"
    elif "hepsiburada" in source_lower:
        return f"https://www.hepsiburada.com/ara?q={query_encoded}"
    elif "n11" in source_lower:
        return f"https://www.n11.com/arama?q={query_encoded}"
    elif "boyner" in source_lower:
        return f"https://www.boyner.com.tr/arama?q={query_encoded}"

    return google_link

# -------------------------
# SERP API (GÃœÃ‡LENDÄ°RÄ°LMÄ°Åž)
# -------------------------
def fetch_serp_products(query):
    results = []
    api_key = getattr(settings, "SERP_API_KEY", os.getenv("SERP_API_KEY", "")).strip()

    if not api_key:
        print("SERP API KEY bulunamadÄ±")
        return results

    params = {
        "engine": "google_shopping",
        "q": query,
        "api_key": api_key,
        "gl": "tr",
        "hl": "tr",
        "direct_link": "true"
    }

    try:
        response = requests.get("https://serpapi.com/search.json", params=params, timeout=10)
        data = response.json()
        shopping_results = data.get("shopping_results", [])

        for i, p in enumerate(shopping_results[:15]):
            p_id = f"serp_{i}_{random.randint(1000,9999)}"
            
            # Ham linki al
            raw_link = p.get("direct_link")
            offers = p.get("offers")
            if not raw_link and offers and isinstance(offers, list) and len(offers) > 0:
                raw_link = offers[0].get("link")
            if not raw_link:
                raw_link = p.get("product_link") or p.get("link") or "#"

            # FÄ°NDA DOKUNUÅžU: Linki maÄŸazaya zorla
            product_title = p.get("title", "")
            source_name = p.get("source", "")
            final_link = extract_real_link(raw_link, product_title, source_name)

            # Site Renkleri
            source_lower = source_name.lower()
            site_color = "warning"
            if "trendyol" in source_lower: site_color = "orange"
            elif "hepsiburada" in source_lower: site_color = "hb"
            elif "amazon" in source_lower: site_color = "amazon"
            elif "n11" in source_lower: site_color = "n11"
            elif "boyner" in source_lower: site_color = "boyner"

            results.append({
                "id": p_id,
                "title": product_title,
                "price": p.get("price", "Fiyat yok"),
                "image": p.get("thumbnail") or p.get("image"),
                "brand": source_name,
                "rating": p.get("rating", 0),
                "review_count": p.get("reviews", 0),
                "site": source_name,
                "site_color": site_color,
                "delivery_info": p.get("delivery", "MaÄŸaza DetayÄ±"),
                "positive_ratio": int(p.get("rating", 0) * 20) if p.get("rating") else 0,
                "review_summary": "",
                "description": p.get("snippet", ""),
                "link": final_link
            })
    except Exception as e:
        print("SerpAPI Error:", e)

    return results

# -------------------------
# DEMO APIs (FakeStore + DummyJSON)
# -------------------------
def fetch_demo_products(query):
    results = []
    query_words = query.lower().split()
    try:
        res = requests.get("https://fakestoreapi.com/products", timeout=5)
        for p in res.json():
            title_lower = p["title"].lower()
            if query_words and not all(word in title_lower for word in query_words):
                continue
            results.append({
                "id": f"fs_{p['id']}",
                "title": p["title"],
                "price": f"{p['price']} $",
                "image": p["image"],
                "rating": p.get("rating", {}).get("rate", 0),
                "review_count": p.get("rating", {}).get("count", 0),
                "site": "FakeStore",
                "site_color": "primary",
                "delivery_info": "2-3 gÃ¼n",
                "positive_ratio": int(p.get("rating", {}).get("rate", 0) * 20),
                "link": "#"
            })
    except: pass
    return results

# -------------------------
# DEDUPLICATION LOGIC
# -------------------------
def deduplicate_products(products):
    """FarklÄ± maÄŸazalardan gelen aynÄ± Ã¼rÃ¼nleri kaldÄ±r (baÅŸlÄ±ÄŸa gÃ¶re)"""
    seen = set()
    unique = []
    
    for p in products:
        # Sadece title'a gÃ¶re normalize et (site fark etmez)
        title_normalized = normalize_title(p.get("title", ""))
        
        # Ä°lk 50 karakteri al (Ã¼rÃ¼n ismi gerÃ§ekten benzerse algÄ±lanabilmesi iÃ§in)
        key = title_normalized[:50]
        
        if key not in seen and key:  # BoÅŸ title almamak iÃ§in
            seen.add(key)
            unique.append(p)
    
    return unique


# -------------------------
# MAIN ENTRY
# -------------------------
def get_all_products(query, compare_mode=False):
    """
    query: Aranacak Ã¼rÃ¼n/baÅŸlÄ±k
    compare_mode: True = AynÄ± Ã¼rÃ¼n farklÄ± satÄ±cÄ±lardan (5 satÄ±cÄ±), 
                  False = Benzersiz Ã¼rÃ¼nler (dedupe)
    """
    now = time.time()

    # cache varsa ve sÃ¼resi geÃ§mediyse
    cache_key = f"{query}_{compare_mode}"
    if cache_key in CACHE:
        cached_data, cached_time = CACHE[cache_key]
        if now - cached_time < 600:
            print("âœ… CACHE'DEN GELDÄ°:", query, f"(compare_mode={compare_mode})")
            return cached_data
        else:
            del CACHE[cache_key]

    print("ðŸŒ API'DEN GELDÄ°:", query, f"(compare_mode={compare_mode})")

    results = []
    serp_results = fetch_serp_products(query)
    results.extend(serp_results)

    if len(results) < 5:
        results.extend(fetch_demo_products(query))

    if compare_mode:
        # COMPARE MODE: AynÄ± Ã¼rÃ¼nÃ¼ satÄ±cÄ±lardan getir (max 5)
        results = results[:5]  # Ä°lk 5 satÄ±cÄ±yÄ± al
        print(f"ðŸ“Š COMPARE MODE: {len(results)} satÄ±cÄ± bulundu")
    else:
        # NORMAL MODE: Duplicate Ã¼rÃ¼nleri kaldÄ±r
        results = deduplicate_products(results)
    
    # SÄ±ra karÄ±ÅŸtÄ±r ama en iyileri yukarÄ±ya al (rating + review'e gÃ¶re)
    results.sort(key=lambda x: (
        float(x.get("rating", 0)) or 0,
        int(str(x.get("review_count", 0)).replace(",", "")) or 0
    ), reverse=True)

    CACHE[cache_key] = (results, now)
    return results
